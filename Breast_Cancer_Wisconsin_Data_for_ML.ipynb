{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.3** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-machine-learning/resources/bANLa) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Practice, using Breast Cancer Wisconsin (Diagnostic) Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Breast Cancer Wisconsin (Diagnostic) Database to create a classifier that can help diagnose patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Wisconsin (Diagnostic) Database\n",
      "=============================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "References\n",
      "----------\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "print(cancer.DESCR) # Print the data set description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
      "        1.189e-01],\n",
      "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
      "        8.902e-02],\n",
      "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
      "        8.758e-02],\n",
      "       ...,\n",
      "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
      "        7.820e-02],\n",
      "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
      "        1.240e-01],\n",
      "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
      "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': 'Breast Cancer Wisconsin (Diagnostic) Database\\n=============================================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\nReferences\\n----------\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.\\n', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error',\n",
      "       'fractal dimension error', 'worst radius', 'worst texture',\n",
      "       'worst perimeter', 'worst area', 'worst smoothness',\n",
      "       'worst compactness', 'worst concavity', 'worst concave points',\n",
      "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(cancer)\n",
    "print(len(cancer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object returned by `load_breast_cancer()` is a scikit-learn Bunch object, which is similar to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Breast Cancer Wisconsin (Diagnostic) Database\\n=============================================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\nReferences\\n----------\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer['DESCR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "print(type(cancer))\n",
    "\n",
    "# scikit learn bunch object. this is similar to dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question to ask: 0\n",
    "\n",
    "How many features does the breast cancer dataset have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_zero():\n",
    "    # This function returns the number of features of the breast cancer dataset, which is an integer. \n",
    "    # The assignment question description will tell you the general format the autograder is expecting\n",
    "    return len(cancer['feature_names'])\n",
    "answer_zero() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question to ask: 1\n",
    "\n",
    "Convert the sklearn.dataset `cancer` to a DataFrame. \n",
    "\n",
    "*This function returns a `(569, 31)` DataFrame with * \n",
    "\n",
    "*columns = *\n",
    "\n",
    "    ['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
    "    'mean smoothness', 'mean compactness', 'mean concavity',\n",
    "    'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
    "    'radius error', 'texture error', 'perimeter error', 'area error',\n",
    "    'smoothness error', 'compactness error', 'concavity error',\n",
    "    'concave points error', 'symmetry error', 'fractal dimension error',\n",
    "    'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
    "    'worst smoothness', 'worst compactness', 'worst concavity',\n",
    "    'worst concave points', 'worst symmetry', 'worst fractal dimension',\n",
    "    'target']\n",
    "\n",
    "*and index = *\n",
    "\n",
    "    RangeIndex(start=0, stop=569, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the dataset to a DataFrame helps make many things easier such as munging data\n",
    "\n",
    "def answer_one():\n",
    "    df = pd.DataFrame(cancer.data, columns=cancer['feature_names'])\n",
    "    df['target']=cancer['target']\n",
    "    return df\n",
    "\n",
    "answer_one().shape\n",
    "\n",
    "# df.shape: Get the number of rows and number of columns in pandas dataframe python\n",
    "# RangeIndex(start=0, stop=569, step=1) means that index 569 is not included\n",
    "# 'target' column was added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question to ask: 2\n",
    "What is the class distribution? (i.e. how many instances of `malignant` (encoded 0) and how many `benign` (encoded 1)?)\n",
    "\n",
    "*This function returns a Series named `target` of length 2 with integer values and index =* `['malignant', 'benign']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "benign       357\n",
       "malignant    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(type(cancer)) # <class 'sklearn.utils.Bunch'>, I need to use dataframe, not sklearn bunch\n",
    "\n",
    "def answer_two():\n",
    "    cancerdf = answer_one()\n",
    "    class_distribution = cancerdf['target'].value_counts()\n",
    "#     change index\n",
    "    class_distribution.index = ['benign','malignant']\n",
    "    \n",
    "    return class_distribution\n",
    "\n",
    "print(type(answer_two()))\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question to ask: 3\n",
    "Splitting the DataFrame into `X` (the data) and `y` (the labels).\n",
    "\n",
    "*This function should return a tuple of length 2:* `(X, y)`*, where* \n",
    "* `X`*, a pandas DataFrame, has shape* `(569, 30)`\n",
    "* `y`*, a pandas Series, has shape* `(569,)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       " 0         17.990         10.38          122.80     1001.0          0.11840   \n",
       " 1         20.570         17.77          132.90     1326.0          0.08474   \n",
       " 2         19.690         21.25          130.00     1203.0          0.10960   \n",
       " 3         11.420         20.38           77.58      386.1          0.14250   \n",
       " 4         20.290         14.34          135.10     1297.0          0.10030   \n",
       " 5         12.450         15.70           82.57      477.1          0.12780   \n",
       " 6         18.250         19.98          119.60     1040.0          0.09463   \n",
       " 7         13.710         20.83           90.20      577.9          0.11890   \n",
       " 8         13.000         21.82           87.50      519.8          0.12730   \n",
       " 9         12.460         24.04           83.97      475.9          0.11860   \n",
       " 10        16.020         23.24          102.70      797.8          0.08206   \n",
       " 11        15.780         17.89          103.60      781.0          0.09710   \n",
       " 12        19.170         24.80          132.40     1123.0          0.09740   \n",
       " 13        15.850         23.95          103.70      782.7          0.08401   \n",
       " 14        13.730         22.61           93.60      578.3          0.11310   \n",
       " 15        14.540         27.54           96.73      658.8          0.11390   \n",
       " 16        14.680         20.13           94.74      684.5          0.09867   \n",
       " 17        16.130         20.68          108.10      798.8          0.11700   \n",
       " 18        19.810         22.15          130.00     1260.0          0.09831   \n",
       " 19        13.540         14.36           87.46      566.3          0.09779   \n",
       " 20        13.080         15.71           85.63      520.0          0.10750   \n",
       " 21         9.504         12.44           60.34      273.9          0.10240   \n",
       " 22        15.340         14.26          102.50      704.4          0.10730   \n",
       " 23        21.160         23.04          137.20     1404.0          0.09428   \n",
       " 24        16.650         21.38          110.00      904.6          0.11210   \n",
       " 25        17.140         16.40          116.00      912.7          0.11860   \n",
       " 26        14.580         21.53           97.41      644.8          0.10540   \n",
       " 27        18.610         20.25          122.10     1094.0          0.09440   \n",
       " 28        15.300         25.27          102.40      732.4          0.10820   \n",
       " 29        17.570         15.05          115.00      955.1          0.09847   \n",
       " ..           ...           ...             ...        ...              ...   \n",
       " 539        7.691         25.44           48.34      170.4          0.08668   \n",
       " 540       11.540         14.44           74.65      402.9          0.09984   \n",
       " 541       14.470         24.99           95.81      656.4          0.08837   \n",
       " 542       14.740         25.42           94.70      668.6          0.08275   \n",
       " 543       13.210         28.06           84.88      538.4          0.08671   \n",
       " 544       13.870         20.70           89.77      584.8          0.09578   \n",
       " 545       13.620         23.23           87.19      573.2          0.09246   \n",
       " 546       10.320         16.35           65.31      324.9          0.09434   \n",
       " 547       10.260         16.58           65.85      320.8          0.08877   \n",
       " 548        9.683         19.34           61.05      285.7          0.08491   \n",
       " 549       10.820         24.21           68.89      361.6          0.08192   \n",
       " 550       10.860         21.48           68.51      360.5          0.07431   \n",
       " 551       11.130         22.44           71.49      378.4          0.09566   \n",
       " 552       12.770         29.43           81.35      507.9          0.08276   \n",
       " 553        9.333         21.94           59.01      264.0          0.09240   \n",
       " 554       12.880         28.92           82.50      514.3          0.08123   \n",
       " 555       10.290         27.61           65.67      321.4          0.09030   \n",
       " 556       10.160         19.59           64.73      311.7          0.10030   \n",
       " 557        9.423         27.88           59.26      271.3          0.08123   \n",
       " 558       14.590         22.68           96.39      657.1          0.08473   \n",
       " 559       11.510         23.93           74.52      403.5          0.09261   \n",
       " 560       14.050         27.15           91.38      600.4          0.09929   \n",
       " 561       11.200         29.37           70.67      386.0          0.07449   \n",
       " 562       15.220         30.62          103.40      716.9          0.10480   \n",
       " 563       20.920         25.09          143.00     1347.0          0.10990   \n",
       " 564       21.560         22.39          142.00     1479.0          0.11100   \n",
       " 565       20.130         28.25          131.20     1261.0          0.09780   \n",
       " 566       16.600         28.08          108.30      858.1          0.08455   \n",
       " 567       20.600         29.33          140.10     1265.0          0.11780   \n",
       " 568        7.760         24.54           47.92      181.0          0.05263   \n",
       " \n",
       "      mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       " 0             0.27760        0.300100             0.147100         0.2419   \n",
       " 1             0.07864        0.086900             0.070170         0.1812   \n",
       " 2             0.15990        0.197400             0.127900         0.2069   \n",
       " 3             0.28390        0.241400             0.105200         0.2597   \n",
       " 4             0.13280        0.198000             0.104300         0.1809   \n",
       " 5             0.17000        0.157800             0.080890         0.2087   \n",
       " 6             0.10900        0.112700             0.074000         0.1794   \n",
       " 7             0.16450        0.093660             0.059850         0.2196   \n",
       " 8             0.19320        0.185900             0.093530         0.2350   \n",
       " 9             0.23960        0.227300             0.085430         0.2030   \n",
       " 10            0.06669        0.032990             0.033230         0.1528   \n",
       " 11            0.12920        0.099540             0.066060         0.1842   \n",
       " 12            0.24580        0.206500             0.111800         0.2397   \n",
       " 13            0.10020        0.099380             0.053640         0.1847   \n",
       " 14            0.22930        0.212800             0.080250         0.2069   \n",
       " 15            0.15950        0.163900             0.073640         0.2303   \n",
       " 16            0.07200        0.073950             0.052590         0.1586   \n",
       " 17            0.20220        0.172200             0.102800         0.2164   \n",
       " 18            0.10270        0.147900             0.094980         0.1582   \n",
       " 19            0.08129        0.066640             0.047810         0.1885   \n",
       " 20            0.12700        0.045680             0.031100         0.1967   \n",
       " 21            0.06492        0.029560             0.020760         0.1815   \n",
       " 22            0.21350        0.207700             0.097560         0.2521   \n",
       " 23            0.10220        0.109700             0.086320         0.1769   \n",
       " 24            0.14570        0.152500             0.091700         0.1995   \n",
       " 25            0.22760        0.222900             0.140100         0.3040   \n",
       " 26            0.18680        0.142500             0.087830         0.2252   \n",
       " 27            0.10660        0.149000             0.077310         0.1697   \n",
       " 28            0.16970        0.168300             0.087510         0.1926   \n",
       " 29            0.11570        0.098750             0.079530         0.1739   \n",
       " ..                ...             ...                  ...            ...   \n",
       " 539           0.11990        0.092520             0.013640         0.2037   \n",
       " 540           0.11200        0.067370             0.025940         0.1818   \n",
       " 541           0.12300        0.100900             0.038900         0.1872   \n",
       " 542           0.07214        0.041050             0.030270         0.1840   \n",
       " 543           0.06877        0.029870             0.032750         0.1628   \n",
       " 544           0.10180        0.036880             0.023690         0.1620   \n",
       " 545           0.06747        0.029740             0.024430         0.1664   \n",
       " 546           0.04994        0.010120             0.005495         0.1885   \n",
       " 547           0.08066        0.043580             0.024380         0.1669   \n",
       " 548           0.05030        0.023370             0.009615         0.1580   \n",
       " 549           0.06602        0.015480             0.008160         0.1976   \n",
       " 550           0.04227        0.000000             0.000000         0.1661   \n",
       " 551           0.08194        0.048240             0.022570         0.2030   \n",
       " 552           0.04234        0.019970             0.014990         0.1539   \n",
       " 553           0.05605        0.039960             0.012820         0.1692   \n",
       " 554           0.05824        0.061950             0.023430         0.1566   \n",
       " 555           0.07658        0.059990             0.027380         0.1593   \n",
       " 556           0.07504        0.005025             0.011160         0.1791   \n",
       " 557           0.04971        0.000000             0.000000         0.1742   \n",
       " 558           0.13300        0.102900             0.037360         0.1454   \n",
       " 559           0.10210        0.111200             0.041050         0.1388   \n",
       " 560           0.11260        0.044620             0.043040         0.1537   \n",
       " 561           0.03558        0.000000             0.000000         0.1060   \n",
       " 562           0.20870        0.255000             0.094290         0.2128   \n",
       " 563           0.22360        0.317400             0.147400         0.2149   \n",
       " 564           0.11590        0.243900             0.138900         0.1726   \n",
       " 565           0.10340        0.144000             0.097910         0.1752   \n",
       " 566           0.10230        0.092510             0.053020         0.1590   \n",
       " 567           0.27700        0.351400             0.152000         0.2397   \n",
       " 568           0.04362        0.000000             0.000000         0.1587   \n",
       " \n",
       "      mean fractal dimension           ...             worst radius  \\\n",
       " 0                   0.07871           ...                   25.380   \n",
       " 1                   0.05667           ...                   24.990   \n",
       " 2                   0.05999           ...                   23.570   \n",
       " 3                   0.09744           ...                   14.910   \n",
       " 4                   0.05883           ...                   22.540   \n",
       " 5                   0.07613           ...                   15.470   \n",
       " 6                   0.05742           ...                   22.880   \n",
       " 7                   0.07451           ...                   17.060   \n",
       " 8                   0.07389           ...                   15.490   \n",
       " 9                   0.08243           ...                   15.090   \n",
       " 10                  0.05697           ...                   19.190   \n",
       " 11                  0.06082           ...                   20.420   \n",
       " 12                  0.07800           ...                   20.960   \n",
       " 13                  0.05338           ...                   16.840   \n",
       " 14                  0.07682           ...                   15.030   \n",
       " 15                  0.07077           ...                   17.460   \n",
       " 16                  0.05922           ...                   19.070   \n",
       " 17                  0.07356           ...                   20.960   \n",
       " 18                  0.05395           ...                   27.320   \n",
       " 19                  0.05766           ...                   15.110   \n",
       " 20                  0.06811           ...                   14.500   \n",
       " 21                  0.06905           ...                   10.230   \n",
       " 22                  0.07032           ...                   18.070   \n",
       " 23                  0.05278           ...                   29.170   \n",
       " 24                  0.06330           ...                   26.460   \n",
       " 25                  0.07413           ...                   22.250   \n",
       " 26                  0.06924           ...                   17.620   \n",
       " 27                  0.05699           ...                   21.310   \n",
       " 28                  0.06540           ...                   20.270   \n",
       " 29                  0.06149           ...                   20.010   \n",
       " ..                      ...           ...                      ...   \n",
       " 539                 0.07751           ...                    8.678   \n",
       " 540                 0.06782           ...                   12.260   \n",
       " 541                 0.06341           ...                   16.220   \n",
       " 542                 0.05680           ...                   16.510   \n",
       " 543                 0.05781           ...                   14.370   \n",
       " 544                 0.06688           ...                   15.050   \n",
       " 545                 0.05801           ...                   15.350   \n",
       " 546                 0.06201           ...                   11.250   \n",
       " 547                 0.06714           ...                   10.830   \n",
       " 548                 0.06235           ...                   10.930   \n",
       " 549                 0.06328           ...                   13.030   \n",
       " 550                 0.05948           ...                   11.660   \n",
       " 551                 0.06552           ...                   12.020   \n",
       " 552                 0.05637           ...                   13.870   \n",
       " 553                 0.06576           ...                    9.845   \n",
       " 554                 0.05708           ...                   13.890   \n",
       " 555                 0.06127           ...                   10.840   \n",
       " 556                 0.06331           ...                   10.650   \n",
       " 557                 0.06059           ...                   10.490   \n",
       " 558                 0.06147           ...                   15.480   \n",
       " 559                 0.06570           ...                   12.480   \n",
       " 560                 0.06171           ...                   15.300   \n",
       " 561                 0.05502           ...                   11.920   \n",
       " 562                 0.07152           ...                   17.520   \n",
       " 563                 0.06879           ...                   24.290   \n",
       " 564                 0.05623           ...                   25.450   \n",
       " 565                 0.05533           ...                   23.690   \n",
       " 566                 0.05648           ...                   18.980   \n",
       " 567                 0.07016           ...                   25.740   \n",
       " 568                 0.05884           ...                    9.456   \n",
       " \n",
       "      worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       " 0            17.33           184.60      2019.0           0.16220   \n",
       " 1            23.41           158.80      1956.0           0.12380   \n",
       " 2            25.53           152.50      1709.0           0.14440   \n",
       " 3            26.50            98.87       567.7           0.20980   \n",
       " 4            16.67           152.20      1575.0           0.13740   \n",
       " 5            23.75           103.40       741.6           0.17910   \n",
       " 6            27.66           153.20      1606.0           0.14420   \n",
       " 7            28.14           110.60       897.0           0.16540   \n",
       " 8            30.73           106.20       739.3           0.17030   \n",
       " 9            40.68            97.65       711.4           0.18530   \n",
       " 10           33.88           123.80      1150.0           0.11810   \n",
       " 11           27.28           136.50      1299.0           0.13960   \n",
       " 12           29.94           151.70      1332.0           0.10370   \n",
       " 13           27.66           112.00       876.5           0.11310   \n",
       " 14           32.01           108.80       697.7           0.16510   \n",
       " 15           37.13           124.10       943.2           0.16780   \n",
       " 16           30.88           123.40      1138.0           0.14640   \n",
       " 17           31.48           136.80      1315.0           0.17890   \n",
       " 18           30.88           186.80      2398.0           0.15120   \n",
       " 19           19.26            99.70       711.2           0.14400   \n",
       " 20           20.49            96.09       630.5           0.13120   \n",
       " 21           15.66            65.13       314.9           0.13240   \n",
       " 22           19.08           125.10       980.9           0.13900   \n",
       " 23           35.59           188.00      2615.0           0.14010   \n",
       " 24           31.56           177.00      2215.0           0.18050   \n",
       " 25           21.40           152.40      1461.0           0.15450   \n",
       " 26           33.21           122.40       896.9           0.15250   \n",
       " 27           27.26           139.90      1403.0           0.13380   \n",
       " 28           36.71           149.30      1269.0           0.16410   \n",
       " 29           19.52           134.90      1227.0           0.12550   \n",
       " ..             ...              ...         ...               ...   \n",
       " 539          31.89            54.49       223.6           0.15960   \n",
       " 540          19.68            78.78       457.8           0.13450   \n",
       " 541          31.73           113.50       808.9           0.13400   \n",
       " 542          32.29           107.40       826.4           0.10600   \n",
       " 543          37.17            92.48       629.6           0.10720   \n",
       " 544          24.75            99.17       688.6           0.12640   \n",
       " 545          29.09            97.58       729.8           0.12160   \n",
       " 546          21.77            71.12       384.9           0.12850   \n",
       " 547          22.04            71.08       357.4           0.14610   \n",
       " 548          25.59            69.10       364.2           0.11990   \n",
       " 549          31.45            83.90       505.6           0.12040   \n",
       " 550          24.77            74.08       412.3           0.10010   \n",
       " 551          28.26            77.80       436.6           0.10870   \n",
       " 552          36.00            88.10       594.7           0.12340   \n",
       " 553          25.05            62.86       295.8           0.11030   \n",
       " 554          35.74            88.84       595.7           0.12270   \n",
       " 555          34.91            69.57       357.6           0.13840   \n",
       " 556          22.88            67.88       347.3           0.12650   \n",
       " 557          34.24            66.50       330.6           0.10730   \n",
       " 558          27.27           105.90       733.5           0.10260   \n",
       " 559          37.16            82.28       474.2           0.12980   \n",
       " 560          33.17           100.20       706.7           0.12410   \n",
       " 561          38.30            75.19       439.6           0.09267   \n",
       " 562          42.79           128.70       915.0           0.14170   \n",
       " 563          29.41           179.10      1819.0           0.14070   \n",
       " 564          26.40           166.10      2027.0           0.14100   \n",
       " 565          38.25           155.00      1731.0           0.11660   \n",
       " 566          34.12           126.70      1124.0           0.11390   \n",
       " 567          39.42           184.60      1821.0           0.16500   \n",
       " 568          30.37            59.16       268.6           0.08996   \n",
       " \n",
       "      worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       " 0              0.66560          0.71190               0.26540          0.4601   \n",
       " 1              0.18660          0.24160               0.18600          0.2750   \n",
       " 2              0.42450          0.45040               0.24300          0.3613   \n",
       " 3              0.86630          0.68690               0.25750          0.6638   \n",
       " 4              0.20500          0.40000               0.16250          0.2364   \n",
       " 5              0.52490          0.53550               0.17410          0.3985   \n",
       " 6              0.25760          0.37840               0.19320          0.3063   \n",
       " 7              0.36820          0.26780               0.15560          0.3196   \n",
       " 8              0.54010          0.53900               0.20600          0.4378   \n",
       " 9              1.05800          1.10500               0.22100          0.4366   \n",
       " 10             0.15510          0.14590               0.09975          0.2948   \n",
       " 11             0.56090          0.39650               0.18100          0.3792   \n",
       " 12             0.39030          0.36390               0.17670          0.3176   \n",
       " 13             0.19240          0.23220               0.11190          0.2809   \n",
       " 14             0.77250          0.69430               0.22080          0.3596   \n",
       " 15             0.65770          0.70260               0.17120          0.4218   \n",
       " 16             0.18710          0.29140               0.16090          0.3029   \n",
       " 17             0.42330          0.47840               0.20730          0.3706   \n",
       " 18             0.31500          0.53720               0.23880          0.2768   \n",
       " 19             0.17730          0.23900               0.12880          0.2977   \n",
       " 20             0.27760          0.18900               0.07283          0.3184   \n",
       " 21             0.11480          0.08867               0.06227          0.2450   \n",
       " 22             0.59540          0.63050               0.23930          0.4667   \n",
       " 23             0.26000          0.31550               0.20090          0.2822   \n",
       " 24             0.35780          0.46950               0.20950          0.3613   \n",
       " 25             0.39490          0.38530               0.25500          0.4066   \n",
       " 26             0.66430          0.55390               0.27010          0.4264   \n",
       " 27             0.21170          0.34460               0.14900          0.2341   \n",
       " 28             0.61100          0.63350               0.20240          0.4027   \n",
       " 29             0.28120          0.24890               0.14560          0.2756   \n",
       " ..                 ...              ...                   ...             ...   \n",
       " 539            0.30640          0.33930               0.05000          0.2790   \n",
       " 540            0.21180          0.17970               0.06918          0.2329   \n",
       " 541            0.42020          0.40400               0.12050          0.3187   \n",
       " 542            0.13760          0.16110               0.10950          0.2722   \n",
       " 543            0.13810          0.10620               0.07958          0.2473   \n",
       " 544            0.20370          0.13770               0.06845          0.2249   \n",
       " 545            0.15170          0.10490               0.07174          0.2642   \n",
       " 546            0.08842          0.04384               0.02381          0.2681   \n",
       " 547            0.22460          0.17830               0.08333          0.2691   \n",
       " 548            0.09546          0.09350               0.03846          0.2552   \n",
       " 549            0.16330          0.06194               0.03264          0.3059   \n",
       " 550            0.07348          0.00000               0.00000          0.2458   \n",
       " 551            0.17820          0.15640               0.06413          0.3169   \n",
       " 552            0.10640          0.08653               0.06498          0.2407   \n",
       " 553            0.08298          0.07993               0.02564          0.2435   \n",
       " 554            0.16200          0.24390               0.06493          0.2372   \n",
       " 555            0.17100          0.20000               0.09127          0.2226   \n",
       " 556            0.12000          0.01005               0.02232          0.2262   \n",
       " 557            0.07158          0.00000               0.00000          0.2475   \n",
       " 558            0.31710          0.36620               0.11050          0.2258   \n",
       " 559            0.25170          0.36300               0.09653          0.2112   \n",
       " 560            0.22640          0.13260               0.10480          0.2250   \n",
       " 561            0.05494          0.00000               0.00000          0.1566   \n",
       " 562            0.79170          1.17000               0.23560          0.4089   \n",
       " 563            0.41860          0.65990               0.25420          0.2929   \n",
       " 564            0.21130          0.41070               0.22160          0.2060   \n",
       " 565            0.19220          0.32150               0.16280          0.2572   \n",
       " 566            0.30940          0.34030               0.14180          0.2218   \n",
       " 567            0.86810          0.93870               0.26500          0.4087   \n",
       " 568            0.06444          0.00000               0.00000          0.2871   \n",
       " \n",
       "      worst fractal dimension  \n",
       " 0                    0.11890  \n",
       " 1                    0.08902  \n",
       " 2                    0.08758  \n",
       " 3                    0.17300  \n",
       " 4                    0.07678  \n",
       " 5                    0.12440  \n",
       " 6                    0.08368  \n",
       " 7                    0.11510  \n",
       " 8                    0.10720  \n",
       " 9                    0.20750  \n",
       " 10                   0.08452  \n",
       " 11                   0.10480  \n",
       " 12                   0.10230  \n",
       " 13                   0.06287  \n",
       " 14                   0.14310  \n",
       " 15                   0.13410  \n",
       " 16                   0.08216  \n",
       " 17                   0.11420  \n",
       " 18                   0.07615  \n",
       " 19                   0.07259  \n",
       " 20                   0.08183  \n",
       " 21                   0.07773  \n",
       " 22                   0.09946  \n",
       " 23                   0.07526  \n",
       " 24                   0.09564  \n",
       " 25                   0.10590  \n",
       " 26                   0.12750  \n",
       " 27                   0.07421  \n",
       " 28                   0.09876  \n",
       " 29                   0.07919  \n",
       " ..                       ...  \n",
       " 539                  0.10660  \n",
       " 540                  0.08134  \n",
       " 541                  0.10230  \n",
       " 542                  0.06956  \n",
       " 543                  0.06443  \n",
       " 544                  0.08492  \n",
       " 545                  0.06953  \n",
       " 546                  0.07399  \n",
       " 547                  0.09479  \n",
       " 548                  0.07920  \n",
       " 549                  0.07626  \n",
       " 550                  0.06592  \n",
       " 551                  0.08032  \n",
       " 552                  0.06484  \n",
       " 553                  0.07393  \n",
       " 554                  0.07242  \n",
       " 555                  0.08283  \n",
       " 556                  0.06742  \n",
       " 557                  0.06969  \n",
       " 558                  0.08004  \n",
       " 559                  0.08732  \n",
       " 560                  0.08321  \n",
       " 561                  0.05905  \n",
       " 562                  0.14090  \n",
       " 563                  0.09873  \n",
       " 564                  0.07115  \n",
       " 565                  0.06637  \n",
       " 566                  0.07820  \n",
       " 567                  0.12400  \n",
       " 568                  0.07039  \n",
       " \n",
       " [569 rows x 30 columns], 0      0\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       " 5      0\n",
       " 6      0\n",
       " 7      0\n",
       " 8      0\n",
       " 9      0\n",
       " 10     0\n",
       " 11     0\n",
       " 12     0\n",
       " 13     0\n",
       " 14     0\n",
       " 15     0\n",
       " 16     0\n",
       " 17     0\n",
       " 18     0\n",
       " 19     1\n",
       " 20     1\n",
       " 21     1\n",
       " 22     0\n",
       " 23     0\n",
       " 24     0\n",
       " 25     0\n",
       " 26     0\n",
       " 27     0\n",
       " 28     0\n",
       " 29     0\n",
       "       ..\n",
       " 539    1\n",
       " 540    1\n",
       " 541    1\n",
       " 542    1\n",
       " 543    1\n",
       " 544    1\n",
       " 545    1\n",
       " 546    1\n",
       " 547    1\n",
       " 548    1\n",
       " 549    1\n",
       " 550    1\n",
       " 551    1\n",
       " 552    1\n",
       " 553    1\n",
       " 554    1\n",
       " 555    1\n",
       " 556    1\n",
       " 557    1\n",
       " 558    1\n",
       " 559    1\n",
       " 560    1\n",
       " 561    1\n",
       " 562    0\n",
       " 563    0\n",
       " 564    0\n",
       " 565    0\n",
       " 566    0\n",
       " 567    0\n",
       " 568    1\n",
       " Name: target, Length: 569, dtype: int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_three():\n",
    "    cancerdf = answer_one()\n",
    "    X = cancerdf[cancerdf.columns[:30]]\n",
    "#     y = cancerdf[cancerdf.columns[30:]] # this is dataframe\n",
    "    y = cancerdf['target'] # this is Series\n",
    "    return (X, y)\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question to ask: 4\n",
    "Using `train_test_split`, split `X` and `y` into training and test sets `(X_train, X_test, y_train, and y_test)`.\n",
    "\n",
    "**Set the random number generator state to 0 using `random_state=0` to make sure your results match the autograder!**\n",
    "\n",
    "*This function returns a tuple of length 4:* `(X_train, X_test, y_train, y_test)`*, where* \n",
    "* `X_train` *has shape* `(426, 30)`\n",
    "* `X_test` *has shape* `(143, 30)`\n",
    "* `y_train` *has shape* `(426,)`\n",
    "* `y_test` *has shape* `(143,)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def answer_four():\n",
    "    X, y = answer_three()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question to ask: 5\n",
    "Using KNeighborsClassifier, fit a k-nearest neighbors (knn) classifier with `X_train`, `y_train` and using one nearest neighbor (`n_neighbors = 1`).\n",
    "\n",
    "*This function returns a * `sklearn.neighbors.classification.KNeighborsClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def answer_five():\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "    \n",
    "    return knn.fit(X_train, y_train) # Return your answer\n",
    "\n",
    "answer_five()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question to ask: 6\n",
    "Using the knn classifier, predict the class label using the mean value for each feature.\n",
    "\n",
    "Used `cancerdf.mean()[:-1].values.reshape(1, -1)` which gets the mean value for each feature, ignores the target column, and reshapes the data from 1 dimension to 2 (necessary for the precict method of KNeighborsClassifier).\n",
    "\n",
    "*This function returns a numpy array either `array([ 0.])` or `array([ 1.])`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# About numpy shape/reshape: https://www.sharpsightlabs.com/blog/numpy-reshape-python/\n",
    "# What does -1 mean in numpy reshape?: https://stackoverflow.com/questions/18691084/what-does-1-mean-in-numpy-reshape\n",
    "\n",
    "def answer_six():\n",
    "    cancerdf = answer_one()\n",
    "    means = cancerdf.mean()[:-1].values.reshape(1, -1)\n",
    "#     X_train, X_test, y_train, y_test = answer_four()\n",
    "#     knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "#     knn.fit(X_train, y_train)\n",
    "    knn = answer_five()\n",
    "    label_prediction = knn.predict(means)\n",
    "    \n",
    "    return label_prediction\n",
    "\n",
    "answer_six()\n",
    "\n",
    "# cancerdf = answer_one()\n",
    "# means = cancerdf.mean()[:-1].values.reshape(1, -1)\n",
    "# means = cancerdf.mean()[:-1]\n",
    "# means = cancerdf.mean()[:-1].values\n",
    "# print(type(means))\n",
    "# means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question to ask: 7\n",
    "Using the knn classifier, predict the class labels for the test set `X_test`.\n",
    "\n",
    "*This function returns a numpy array with shape `(143,)` and values either `0.0` or `1.0`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_seven():\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    knn = answer_five()\n",
    "    label_prediction = knn.predict(X_test)\n",
    "    \n",
    "    return label_prediction\n",
    "\n",
    "answer_seven()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question to ask: 8\n",
    "Finding the score (mean accuracy) of your knn classifier using `X_test` and `y_test`.\n",
    "\n",
    "*This function returns a float between 0 and 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.916083916083916"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_eight():\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    knn = answer_five()\n",
    "    \n",
    "    return knn.score(X_test, y_test)\n",
    "\n",
    "answer_eight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "Using the plotting function below to visualize the differet predicition scores between training and test sets, as well as malignant and benign cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "def accuracy_plot():\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "\n",
    "    # Find the training and testing accuracies by target value (i.e. malignant, benign)\n",
    "    mal_train_X = X_train[y_train==0]\n",
    "    mal_train_y = y_train[y_train==0]\n",
    "    ben_train_X = X_train[y_train==1]\n",
    "    ben_train_y = y_train[y_train==1]\n",
    "\n",
    "    mal_test_X = X_test[y_test==0]\n",
    "    mal_test_y = y_test[y_test==0]\n",
    "    ben_test_X = X_test[y_test==1]\n",
    "    ben_test_y = y_test[y_test==1]\n",
    "\n",
    "    knn = answer_five()\n",
    "\n",
    "    scores = [knn.score(mal_train_X, mal_train_y), knn.score(ben_train_X, ben_train_y),\n",
    "              knn.score(mal_test_X, mal_test_y), knn.score(ben_test_X, ben_test_y)]\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot the scores as a bar chart\n",
    "    bars = plt.bar(np.arange(4), scores, color=['#4c72b0','#4c72b0','#55a868','#55a868'])\n",
    "\n",
    "    # directly label the score onto the bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.gca().text(bar.get_x() + bar.get_width()/2, height*.90, '{0:.{1}f}'.format(height, 2),\n",
    "                     ha='center', color='w', fontsize=11)\n",
    "\n",
    "    # remove all the ticks (both axes), and tick labels on the Y axis\n",
    "    plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='off', labelbottom='on')\n",
    "\n",
    "    # remove the frame of the chart\n",
    "    for spine in plt.gca().spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    plt.xticks([0,1,2,3], ['Malignant\\nTraining', 'Benign\\nTraining', 'Malignant\\nTest', 'Benign\\nTest'], alpha=0.8);\n",
    "    plt.title('Training and Test Accuracies for Malignant and Benign Cells', alpha=0.8)\n",
    "accuracy_plot()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "f9SY5",
   "launcher_item_id": "oxndk",
   "part_id": "mh1Vo"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
